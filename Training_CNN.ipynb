{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c267ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf305e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80715796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15020 images belonging to 10 classes.\n",
      "Found 1010 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = r'E:\\gesture\\train'\n",
    "test_path = r'E:\\gesture\\test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7b0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1b262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation =\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82b5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "model.compile(optimizer=SGD(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55373007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1502/1502 [==============================] - 444s 295ms/step - loss: 0.3436 - accuracy: 0.9295 - val_loss: 3.2436 - val_accuracy: 0.6069\n",
      "Epoch 2/10\n",
      "1502/1502 [==============================] - 76s 51ms/step - loss: 0.0879 - accuracy: 0.9821 - val_loss: 3.0593 - val_accuracy: 0.8129\n",
      "Epoch 3/10\n",
      "1502/1502 [==============================] - 76s 51ms/step - loss: 0.0649 - accuracy: 0.9903 - val_loss: 5.2604 - val_accuracy: 0.6614\n",
      "Epoch 4/10\n",
      "1502/1502 [==============================] - 76s 51ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 2.3226 - val_accuracy: 0.8129\n",
      "Epoch 5/10\n",
      "1502/1502 [==============================] - 80s 53ms/step - loss: 4.8781e-04 - accuracy: 0.9998 - val_loss: 2.3479 - val_accuracy: 0.8109\n",
      "Epoch 6/10\n",
      "1502/1502 [==============================] - 77s 51ms/step - loss: 3.7604e-04 - accuracy: 0.9999 - val_loss: 2.3454 - val_accuracy: 0.8188\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b16c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 6.815737724304199; accuracy of 80.0000011920929%\n"
     ]
    }
   ],
   "source": [
    "# For getting next batch of testing imgs...\n",
    "imgs, labels = next(test_batches) \n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "# Once the model is fitted we save the model using model.save()  function.                                    \n",
    "model.save('best_model_dataflair3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02b4d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on a small set of test data--\n",
      "\n",
      "Two   Eight   Four   Four   Five   Eight   Eight   Four   Seven   One   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "Two   Eight   Five   Four   Five   Eight   Eight   Four   Three   One   "
     ]
    }
   ],
   "source": [
    "word_dict = {0:'One',1:'Ten',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810885d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f4374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
